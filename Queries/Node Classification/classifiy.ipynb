{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a567a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 4, column: 8, offset: 83} for query: '\\nMATCH (a:Author)\\nWHERE a.n2vEmbedding is not null AND a.domain is not null\\nRETURN id(a) AS id, a.n2vEmbedding AS features, a.domain AS label\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id              label         0         1         2         3         4  \\\n",
      "0   0           Medicine  0.003019  0.002637  0.002523  0.002926 -0.001466   \n",
      "1   1  Political Science  0.272338 -0.174784 -0.132844  0.018287  0.046531   \n",
      "2   2  Political Science  0.311223 -0.192921 -0.083063  0.056526  0.014732   \n",
      "3   3  Political Science  0.255202 -0.145371 -0.087290 -0.005230  0.045122   \n",
      "4   4          Sociology  0.003016  0.000123 -0.003092 -0.003878  0.002291   \n",
      "\n",
      "          5         6         7  ...       118       119       120       121  \\\n",
      "0  0.000360 -0.002579  0.001358  ...  0.000762  0.000124  0.000113  0.003515   \n",
      "1 -0.416449 -0.178818  1.695201  ...  0.428169  0.165190 -0.736638 -0.333500   \n",
      "2 -0.370717 -0.212007  1.583922  ...  0.413350  0.182450 -0.687881 -0.362872   \n",
      "3 -0.344951 -0.169225  1.385602  ...  0.357039  0.142919 -0.599032 -0.286520   \n",
      "4 -0.002050 -0.000125 -0.000048  ... -0.002238 -0.002664  0.000298  0.003789   \n",
      "\n",
      "        122       123       124       125       126       127  \n",
      "0  0.000922 -0.003300 -0.000926  0.000464  0.002780  0.000634  \n",
      "1 -1.409657 -0.503807 -0.707068  0.596051 -0.227024  0.161801  \n",
      "2 -1.353973 -0.410460 -0.695532  0.583356 -0.180633  0.149430  \n",
      "3 -1.164294 -0.423853 -0.581601  0.493493 -0.193523  0.130568  \n",
      "4 -0.001657 -0.003101  0.000841  0.003591 -0.001375  0.001365  \n",
      "\n",
      "[5 rows x 130 columns]\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (a:Author)\n",
    "WHERE a.n2vEmbedding is not null AND a.domain is not null\n",
    "RETURN id(a) AS id, a.n2vEmbedding AS features, a.domain AS label\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    results = session.run(query)\n",
    "    records = [(r[\"id\"], r[\"features\"], r[\"label\"]) for r in results]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records, columns=[\"id\", \"features\", \"label\"])\n",
    "df[\"features\"] = df[\"features\"].apply(np.array)\n",
    "\n",
    "# Expand features to separate columns\n",
    "features_df = pd.DataFrame(df[\"features\"].tolist())\n",
    "full_df = pd.concat([df[[\"id\", \"label\"]], features_df], axis=1)\n",
    "\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of specific labels to broader categories\n",
    "group_map = {\n",
    "    \"Art\": \"Humanities\",\n",
    "    \"Philosophy\": \"Humanities\",\n",
    "    \"History\": \"Humanities\",\n",
    "    \"Political Science\": \"Social Sciences\",\n",
    "    \"Sociology\": \"Social Sciences\",\n",
    "    \"Psychology\": \"Social Sciences\",\n",
    "    \"Economics\": \"Social Sciences\",\n",
    "    \"Business\": \"Social Sciences\",\n",
    "    \"Biology\": \"Natural Sciences\",\n",
    "    \"Medicine\": \"Life Sciences\",\n",
    "    \"Engineering\": \"Applied Sciences\",\n",
    "    \"Computer Science\": \"Applied Sciences\",\n",
    "    \"Geography\": \"Natural Sciences\",\n",
    "    \"Materials Science\": \"Applied Sciences\",\n",
    "    \"Mathematics\": \"Formal Sciences\"\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "full_df[\"label_grouped\"] = full_df[\"label\"].map(group_map).fillna(full_df[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3aca1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Applied Sciences       1.00      0.12      0.22         8\n",
      "      Humanities       0.00      0.00      0.00        31\n",
      "   Life Sciences       0.94      0.69      0.80      1177\n",
      "Natural Sciences       0.80      0.22      0.34        91\n",
      " Social Sciences       0.90      0.99      0.94      4124\n",
      "\n",
      "        accuracy                           0.90      5431\n",
      "       macro avg       0.73      0.40      0.46      5431\n",
      "    weighted avg       0.90      0.90      0.89      5431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Drop unwanted columns and define X and y using grouped labels\n",
    "X = full_df.drop(columns=[\"id\", \"label\", \"label_grouped\"])\n",
    "y = full_df[\"label_grouped\"]\n",
    "\n",
    "label_counts = y.value_counts()\n",
    "valid_labels = label_counts[label_counts >= 2].index\n",
    "\n",
    "filtered_df = full_df[full_df[\"label_grouped\"].isin(valid_labels)]\n",
    "X = filtered_df.drop(columns=[\"id\", \"label\", \"label_grouped\"])\n",
    "y = filtered_df[\"label_grouped\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04cb0aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Applied Sciences       1.00      1.00      1.00      4124\n",
      "         Geology       1.00      1.00      1.00      4124\n",
      "      Humanities       1.00      1.00      1.00      4124\n",
      "   Life Sciences       0.97      1.00      0.98      4124\n",
      "Natural Sciences       1.00      1.00      1.00      4124\n",
      "         Physics       1.00      1.00      1.00      4124\n",
      " Social Sciences       1.00      0.97      0.98      4124\n",
      "\n",
      "        accuracy                           1.00     28868\n",
      "       macro avg       1.00      1.00      1.00     28868\n",
      "    weighted avg       1.00      1.00      1.00     28868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "X_resampled, y_resampled = RandomOverSampler(random_state=42).fit_resample(X, y)\n",
    "\n",
    "# Now train-test split on balanced data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, stratify=y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13af78f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Applied Sciences       0.80      0.61      0.69      4124\n",
      "         Geology       1.00      1.00      1.00      4124\n",
      "      Humanities       0.44      0.96      0.60      4124\n",
      "   Life Sciences       0.52      0.45      0.48      4124\n",
      "Natural Sciences       0.61      0.56      0.58      4124\n",
      "         Physics       1.00      1.00      1.00      4124\n",
      " Social Sciences       0.43      0.13      0.20      4124\n",
      "\n",
      "        accuracy                           0.67     28868\n",
      "       macro avg       0.69      0.67      0.65     28868\n",
      "    weighted avg       0.69      0.67      0.65     28868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train-test split (after resampling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, stratify=y_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    multi_class=\"multinomial\",  # for softmax behavior\n",
    "    solver=\"lbfgs\",             # efficient for multinomial\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"     # helps with any residual imbalance\n",
    ")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163fe236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:50:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Applied Sciences       1.00      1.00      1.00      4124\n",
      "         Geology       1.00      1.00      1.00      4124\n",
      "      Humanities       1.00      1.00      1.00      4124\n",
      "   Life Sciences       0.95      0.97      0.96      4124\n",
      "Natural Sciences       1.00      1.00      1.00      4124\n",
      "         Physics       1.00      1.00      1.00      4124\n",
      " Social Sciences       0.97      0.94      0.96      4124\n",
      "\n",
      "        accuracy                           0.99     28868\n",
      "       macro avg       0.99      0.99      0.99     28868\n",
      "    weighted avg       0.99      0.99      0.99     28868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_resampled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_encoded, stratify=y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(le.classes_),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_encoded = xgb_clf.predict(X_test)\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "y_test_str = le.inverse_transform(y_test)\n",
    "\n",
    "print(classification_report(y_test_str, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
